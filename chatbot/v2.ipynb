{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necssary libraries\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings #using cohere embeddings and chatcohere moedls for now, can try openai (hopefully a better result with it)\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #usin recursive chunking method for better chunks of vector data\n",
    "from langchain_chroma import Chroma #using chroma moedls for storing vecto data\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain_core.runnables import RunnablePassthrough #using runnables moedls\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import PromptTemplate #used to give prompt\n",
    "from langchain.chains.sql_database.query import create_sql_query_chain #using dedicated langchain chain for processing sql\n",
    "import os\n",
    "from dotenv import load_dotenv #for environment variables\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm query to be processed\n",
    "llm_query = \"Show me the first 10 rock tracks, including the artist name, album title, track name, genre, media type, and price, sorted by artist, album, and track name.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database and LLM\n",
    "load_dotenv()\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "llm = ChatCohere(model=\"command-r-plus\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLTextSplitter(RecursiveCharacterTextSplitter):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            chunk_size=1024,\n",
    "            chunk_overlap=128,\n",
    "            separators=[\n",
    "                \"\\n\\nCREATE TABLE\",\n",
    "                \"\\n\\nALTER TABLE\",\n",
    "                \"\\n\\nINSERT INTO\",\n",
    "                \";\\n\",\n",
    "                \" \"\n",
    "            ],\n",
    "            is_separator_regex=False\n",
    "        )\n",
    "\n",
    "    def split_documents(self, documents):\n",
    "        chunks = super().split_documents(documents)\n",
    "        return self._merge_table_definitions(chunks)\n",
    "\n",
    "    def _merge_table_definitions(self, chunks):\n",
    "        combined = []\n",
    "        current_table = None\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            content = chunk.page_content\n",
    "            if \"CREATE TABLE\" in content:\n",
    "                if current_table:\n",
    "                    combined.append(current_table)\n",
    "                current_table = chunk\n",
    "            elif current_table:\n",
    "                current_table.page_content += \"\\n\" + content\n",
    "            else:\n",
    "                combined.append(chunk)\n",
    "        \n",
    "        if current_table:\n",
    "            combined.append(current_table)\n",
    "            \n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting metadata of related tables using references command present in ddl schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_schema(db):\n",
    "    ddls = []\n",
    "    relationships = {}\n",
    "    \n",
    "    for table_name in db.get_usable_table_names():\n",
    "        ddl = db.get_table_info([table_name])\n",
    "        \n",
    "        # Extract relationships and table properties\n",
    "        references = re.findall(r'REFERENCES\\s+\"?(\\w+)\"?', ddl)\n",
    "        columns = re.findall(r'^\\s*\"?(\\w+)\"?\\s+', ddl, re.MULTILINE)\n",
    "        \n",
    "        # Ensure all metadata fields are present\n",
    "        chunk = Document(\n",
    "            page_content=ddl,\n",
    "            metadata={\n",
    "                \"object_type\": \"table_definition\",\n",
    "                \"table_name\": table_name,\n",
    "                \"related_tables\": \", \".join(references),\n",
    "                \"is_central_table\": int(len(references) > 2),\n",
    "                \"column_count\": len(columns),\n",
    "                \"is_fact_table\": int(\"id\" in [col.lower() for col in columns])\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Filter metadata for Chroma compatibility\n",
    "        chunk.metadata = {k: v for k, v in chunk.metadata.items() \n",
    "                         if isinstance(v, (str, int, float, bool))}\n",
    "        \n",
    "        ddls.append(chunk)\n",
    "        relationships[table_name] = references\n",
    "    \n",
    "    return ddls, relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema retreiver function to retreive embedded chunks from chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaRetriever:\n",
    "    def __init__(self, vector_store, relationship_graph):\n",
    "        self.vector_store = vector_store\n",
    "        self.relationship_graph = relationship_graph\n",
    "        self.base_retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )\n",
    "\n",
    "    def find_related_tables(self, table_name):\n",
    "        # Get documents with metadata from Chroma\n",
    "        collection = self.vector_store._collection.get()\n",
    "        related = []\n",
    "        \n",
    "        for doc, metadata in zip(collection['documents'], collection['metadatas']):\n",
    "            if metadata[\"table_name\"] in self.relationship_graph.get(table_name, []):\n",
    "                related.append(Document(\n",
    "                    page_content=doc,\n",
    "                    metadata=metadata\n",
    "                ))\n",
    "        \n",
    "        print(f\"Found related tables for {table_name}: {[r.metadata['table_name'] for r in related]}\")  # Debug\n",
    "        return related\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        print(f\"Processing query: {query}\")  # Debug\n",
    "        \n",
    "        # Get initial results with scores\n",
    "        docs_scores = self.vector_store.similarity_search_with_score(query, k=15)\n",
    "        print(f\"Initial results with scores: {[(doc.metadata['table_name'], score) for doc, score in docs_scores]}\")  # Debug\n",
    "        \n",
    "        # Adjust score threshold\n",
    "        filtered_docs = [doc for doc, score in docs_scores if score < 0.7]\n",
    "        print(f\"Filtered documents: {[doc.metadata['table_name'] for doc in filtered_docs]}\")  # Debug\n",
    "        \n",
    "        expanded = []\n",
    "        seen = set()\n",
    "        \n",
    "        for doc in filtered_docs:\n",
    "            tbl = doc.metadata.get(\"table_name\")\n",
    "            if tbl and tbl not in seen:\n",
    "                expanded.append(doc)\n",
    "                seen.add(tbl)\n",
    "                # Add related tables\n",
    "                related = self.find_related_tables(tbl)\n",
    "                expanded += [d for d in related if d.metadata[\"table_name\"] not in seen]\n",
    "        \n",
    "        print(f\"Expanded results: {[doc.metadata['table_name'] for doc in expanded]}\")  # Debug\n",
    "        \n",
    "        # Remove duplicates based on table name to avoid any discrepancy\n",
    "        unique_results = []\n",
    "        seen_tables = set()\n",
    "        for doc in expanded:\n",
    "            tbl = doc.metadata[\"table_name\"]\n",
    "            if tbl not in seen_tables:\n",
    "                unique_results.append(doc)\n",
    "                seen_tables.add(tbl)\n",
    "        \n",
    "        # Sort by importance to allow for better sql query generations by llm\n",
    "        sorted_results = sorted(unique_results, \n",
    "                              key=lambda x: (\n",
    "                                  -x.metadata.get(\"is_central_table\", 0),\n",
    "                                  -x.metadata.get(\"column_count\", 0),\n",
    "                                  -x.metadata.get(\"is_fact_table\", 0)\n",
    "                              ))[:7]\n",
    "        \n",
    "        print(f\"Final sorted results: {[doc.metadata['table_name'] for doc in sorted_results]}\")  # Debug\n",
    "        \n",
    "        return sorted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying fucntions and setting chromadb vector_store function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"Chinook.sql\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = SQLTextSplitter()\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "embedding_model = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "chunks, rel_graph = process_schema(db)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"cohere_schema\",\n",
    "    persist_directory=\"./chroma_cohere\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: Show me the first 10 rock tracks, including the artist name, album title, track name, genre, media type, and price, sorted by artist, album, and track name.\n",
      "Initial results with scores: [('Track', 0.5365175604820251), ('Track', 0.5366292595863342), ('Track', 0.5366292595863342), ('Track', 0.5368856191635132), ('Track', 0.5375040173530579), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377929210662842), ('Track', 0.5377929210662842)]\n",
      "Filtered documents: ['Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track']\n",
      "Found related tables for Track: ['Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Expanded results: ['Track', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Final sorted results: ['Track', 'Album', 'Genre', 'MediaType']\n"
     ]
    }
   ],
   "source": [
    "retriever = SchemaRetriever(vector_store, rel_graph)\n",
    "\n",
    "# Example usage for debugging purposes\n",
    "results = retriever.get_relevant_documents(\n",
    "    llm_query\n",
    ")\n",
    "\n",
    "if not results:\n",
    "    print(\"No results found. Checking vector store content...\")\n",
    "    all_docs = vector_store.get()\n",
    "    print(f\"Vector store contains {len(all_docs['documents'])} documents\")\n",
    "    for doc, metadata in zip(all_docs['documents'], all_docs['metadatas']):\n",
    "        print(f\"Document: {doc[:100]}...\")\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: Show me the first 10 rock tracks, including the artist name, album title, track name, genre, media type, and price, sorted by artist, album, and track name.\n",
      "Initial results with scores: [('Track', 0.5365175604820251), ('Track', 0.5366292595863342), ('Track', 0.5366292595863342), ('Track', 0.5368856191635132), ('Track', 0.5375040173530579), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377929210662842), ('Track', 0.5377929210662842)]\n",
      "Filtered documents: ['Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track']\n",
      "Found related tables for Track: ['Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Expanded results: ['Track', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Final sorted results: ['Track', 'Album', 'Genre', 'MediaType']\n",
      "[Document(id='7df93243-ca2a-4b2a-ace7-e8fb5c63f9b1', metadata={'column_count': 19, 'is_central_table': 1, 'is_fact_table': 0, 'object_type': 'table_definition', 'related_tables': 'MediaType, Genre, Album', 'table_name': 'Track'}, page_content='\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tU. Dirkschneider, W. Hoffmann, H. Frank, P. Baltes, S. Kaufmann, G. Hoffmann\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/'), Document(metadata={'is_central_table': 0, 'object_type': 'table_definition', 'related_tables': 'Artist', 'table_name': 'Album'}, page_content='\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/'), Document(metadata={'is_central_table': 0, 'object_type': 'table_definition', 'related_tables': '', 'table_name': 'Genre'}, page_content='\\nCREATE TABLE \"Genre\" (\\n\\t\"GenreId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"GenreId\")\\n)\\n\\n/*\\n3 rows from Genre table:\\nGenreId\\tName\\n1\\tRock\\n2\\tJazz\\n3\\tMetal\\n*/'), Document(metadata={'is_central_table': 0, 'object_type': 'table_definition', 'related_tables': '', 'table_name': 'MediaType'}, page_content='\\nCREATE TABLE \"MediaType\" (\\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"MediaTypeId\")\\n)\\n\\n/*\\n3 rows from MediaType table:\\nMediaTypeId\\tName\\n1\\tMPEG audio file\\n2\\tProtected AAC audio file\\n3\\tProtected MPEG-4 video file\\n*/')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "simple_results = retriever.get_relevant_documents(\n",
    "    llm_query\n",
    ")\n",
    "\n",
    "print(simple_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a chain for processing of query and returning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: Show me the first 10 rock tracks, including the artist name, album title, track name, genre, media type, and price, sorted by artist, album, and track name.\n",
      "Initial results with scores: [('Track', 0.5365175604820251), ('Track', 0.5366292595863342), ('Track', 0.5366292595863342), ('Track', 0.5368856191635132), ('Track', 0.5375040173530579), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377925326584317), ('Track', 0.5377929210662842), ('Track', 0.5377929210662842)]\n",
      "Filtered documents: ['Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track', 'Track']\n",
      "Found related tables for Track: ['Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Expanded results: ['Track', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType', 'Album', 'Genre', 'MediaType']\n",
      "Final sorted results: ['Track', 'Album', 'Genre', 'MediaType']\n",
      "SELECT a.Name AS Artist, al.Title AS Album, t.Name AS Track, g.Name AS Genre, mt.Name AS MediaType, t.UnitPrice\n",
      "FROM Track t\n",
      "JOIN Genre g ON t.GenreId = g.GenreId\n",
      "JOIN MediaType mt ON t.MediaTypeId = mt.MediaTypeId\n",
      "JOIN Album al ON t.AlbumId = al.AlbumId\n",
      "JOIN Artist a ON al.ArtistId = a.ArtistId\n",
      "WHERE g.Name = 'Rock'\n",
      "ORDER BY a.Name, al.Title, t.Name\n",
      "LIMIT 10;\n",
      "[('AC/DC', 'For Those About To Rock We Salute You', 'Breaking The Rules', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'C.O.D.', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Evil Walks', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'For Those About To Rock (We Salute You)', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Inject The Venom', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', \"Let's Get It Up\", 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Night Of The Long Knives', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Put The Finger On You', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Snowballed', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Spellbound', 'Rock', 'MPEG audio file', 0.99)]\n"
     ]
    }
   ],
   "source": [
    "def create_semantic_sql_chain(llm, db, retriever):\n",
    "    \"\"\"Create SQL generation chain with semantic schema retrieval\"\"\"\n",
    "    \n",
    "    # Formatting function for retrieved documents\n",
    "    def format_docs(docs):\n",
    "        formatted = []\n",
    "        for doc in docs:\n",
    "            # Include metadata information in the formatted output\n",
    "            metadata_info = [\n",
    "                f\"Table: {doc.metadata.get('table_name', 'unknown')}\",\n",
    "                f\"Columns: {doc.metadata.get('column_count', 'unknown')}\",\n",
    "                f\"Relationships: {doc.metadata.get('related_tables', 'none')}\"\n",
    "            ]\n",
    "            formatted.append(f\"{doc.page_content}\\nMetadata: {', '.join(metadata_info)}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    template = '''Given an input question, first create a syntactically correct SQL query to run, then look at the results of the query and return the answer.\n",
    "    Use the following format:\n",
    "\n",
    "    Question: \"Question here\"\n",
    "    SQLQuery: \"SQL Query to run\"\n",
    "    SQLResult: \"Result of the SQLQuery\"\n",
    "    Answer: \"Final answer here\"\n",
    "\n",
    "    DO NOT include any markdown formatting, code blocks, or explanation text such as ```sql in start and ``` in end of the SQL query.\n",
    "    ONLY return the SQL query itself, nothing else.\n",
    "    The query should be executable and return the results asked in the question.\n",
    "    You may return up to {top_k} results.\n",
    "\n",
    "    Only use the following tables and their relationships:\n",
    "\n",
    "    {table_info}.\n",
    "\n",
    "    Question: {input}'''\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    # Base SQL query chain\n",
    "    query_chain = create_sql_query_chain(llm, db, prompt)\n",
    "    \n",
    "    # Full chain with semantic retrieval\n",
    "    return (\n",
    "        RunnablePassthrough.assign(\n",
    "            table_info=lambda x: format_docs(retriever.get_relevant_documents(x[\"question\"]))\n",
    "        )\n",
    "        | query_chain\n",
    "    )\n",
    "\n",
    "# Example usagge:\n",
    "chain = create_semantic_sql_chain(llm, db, retriever)\n",
    "result = chain.invoke({\"question\": llm_query})\n",
    "print(result)\n",
    "print(db.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AC/DC', 'For Those About To Rock We Salute You', 'Breaking The Rules', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'C.O.D.', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Evil Walks', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'For Those About To Rock (We Salute You)', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Inject The Venom', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', \"Let's Get It Up\", 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Night Of The Long Knives', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Put The Finger On You', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Snowballed', 'Rock', 'MPEG audio file', 0.99), ('AC/DC', 'For Those About To Rock We Salute You', 'Spellbound', 'Rock', 'MPEG audio file', 0.99)]\n"
     ]
    }
   ],
   "source": [
    "print(db.run(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
