{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'AntÃ´nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.run(\"SELECT * FROM Artist LIMIT 10;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"]=os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "llm = ChatCohere(model=\"command-r-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")\n",
    "\n",
    "\n",
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "system = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([Table])\n",
    "output_parser = PydanticToolsParser(tools=[Table])\n",
    "\n",
    "table_chain = prompt | llm_with_tools | output_parser\n",
    "\n",
    "table_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"Return the names of any SQL tables that are relevant to the user question.\n",
    "The tables are:\n",
    "\n",
    "Music\n",
    "Business\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "category_chain = prompt | llm_with_tools | output_parser\n",
    "category_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTATION of SCHEMA RETREIVAL APPROACH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT a.Name, COUNT(t.TrackId) AS TrackCount\n",
      "FROM Artist a\n",
      "JOIN Album al ON a.ArtistId = al.ArtistId\n",
      "JOIN Track t ON al.AlbumId = t.AlbumId\n",
      "JOIN Genre g ON t.GenreId = g.GenreId\n",
      "WHERE g.Name = 'Rock'\n",
      "GROUP BY a.Name\n",
      "HAVING COUNT(t.TrackId) > 100;\n",
      "[('Led Zeppelin', 114), ('U2', 112)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.sql_database.query import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def setup_vector_store(db):\n",
    "    \"\"\"Store table schemas in ChromaDB with semantic search capabilities\"\"\"\n",
    "    # Get all table DDLs\n",
    "    ddls = [\n",
    "        Document(\n",
    "            page_content=db.get_table_info([table_name]),\n",
    "            metadata={\"table_name\": table_name}\n",
    "        )\n",
    "        for table_name in db.get_usable_table_names()\n",
    "    ]\n",
    "\n",
    "    # Initialize embeddings with Cohere model\n",
    "    embeddings = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "\n",
    "    \n",
    "    # Create vector store\n",
    "    return Chroma.from_documents(\n",
    "        documents=ddls,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"schema_documents\",\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "\n",
    "def create_semantic_sql_chain(llm, db):\n",
    "    \"\"\"Create SQL generation chain with semantic schema retrieval\"\"\"\n",
    "    # Setup vector store\n",
    "    vector_store = setup_vector_store(db)\n",
    "    \n",
    "    # Create retriever for relevant schemas\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "    # Formatting function for retrieved documents\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    template = '''Given an input question, first create a syntactically correct SQL query to run, then look at the results of the query and return the answer.\n",
    "    Use the following format:\n",
    "\n",
    "    Question: \"Question here\"\n",
    "    SQLQuery: \"SQL Query to run\"\n",
    "    SQLResult: \"Result of the SQLQuery\"\n",
    "    Answer: \"Final answer here\"\n",
    "\n",
    "    DO NOT include any markdown formatting, code blocks, or explanation text such as ```sql in start and ``` in end of the SQL query.\n",
    "    ONLY return the SQL query itself, nothing else.\n",
    "    The query should be executable and return the results asked in the question.\n",
    "    You may return up to {top_k} results.\n",
    "\n",
    "    Only use the following tables:\n",
    "\n",
    "    {table_info}.\n",
    "\n",
    "    Question: {input}'''\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    # Base SQL query chain\n",
    "    query_chain = create_sql_query_chain(llm, db,prompt)\n",
    "    \n",
    "    # Full chain with semantic retrieval\n",
    "    return RunnablePassthrough.assign(\n",
    "        table_info=itemgetter(\"question\") | retriever | format_docs\n",
    "    ) | query_chain\n",
    "\n",
    "# Example usage:\n",
    "chain = create_semantic_sql_chain(llm, db)\n",
    "result = chain.invoke({\"question\": \"Which artist has the most tracks in the Rock genre, and how many tracks do they have? Include only artists with more than 100 rock tracks.\"})\n",
    "print(result)\n",
    "print(db.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaching with better chunking and embedding strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SQL file\n",
    "loader = TextLoader(\"chinook.sql\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SQL text splitter\n",
    "sql_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    "    separators=[\n",
    "        \"\\n\\nCREATE TABLE\",  # Split at table definitions\n",
    "        \"\\n\\nALTER TABLE\",   # Split at constraints\n",
    "        \"\\n\\nINSERT INTO\",   # Split data inserts\n",
    "        \";\\n\",               # Split at SQL statement ends\n",
    "        \"\\n\",                # Split at newlines\n",
    "        \" \"                  # Split at spaces as last resort\n",
    "    ],\n",
    "    is_separator_regex=False  # Treat separators as literal strings\n",
    ")\n",
    "\n",
    "chunks = sql_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge broken table definitions\n",
    "combined_chunks = []\n",
    "current_table = None\n",
    "\n",
    "for chunk in chunks:\n",
    "    content = chunk.page_content\n",
    "    if \"CREATE TABLE\" in content:\n",
    "        if current_table:\n",
    "            combined_chunks.append(current_table)\n",
    "        current_table = chunk\n",
    "    elif current_table:\n",
    "        current_table.page_content += \"\\n\" + content\n",
    "    else:\n",
    "        combined_chunks.append(chunk)\n",
    "\n",
    "if current_table:\n",
    "    combined_chunks.append(current_table)\n",
    "\n",
    "chunks = combined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "import re\n",
    "import os\n",
    "\n",
    "embedding_model = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\"\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "def process_chunks(db):\n",
    "    ddls = []\n",
    "    relationships = {}\n",
    "    \n",
    "    for table_name in db.get_usable_table_names():\n",
    "        ddl = db.get_table_info([table_name])\n",
    "        \n",
    "        # Create document with initial metadata\n",
    "        chunk = Document(\n",
    "            page_content=ddl,\n",
    "            metadata={\n",
    "                \"object_type\": \"table_definition\",\n",
    "                \"table_name\": table_name,\n",
    "                \"related_tables\": \", \".join(re.findall(r'REFERENCES\\s+\"?(\\w+)\"?', ddl)),\n",
    "                \"is_central_table\": int(len(re.findall(r'REFERENCES\\s+\"?(\\w+)\"?', ddl)) > 2)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Filter metadata values to Chroma-compatible types\n",
    "        chunk.metadata = {k: v for k, v in chunk.metadata.items() \n",
    "                         if isinstance(v, (str, int, float, bool))}\n",
    "        \n",
    "        ddls.append(chunk)\n",
    "        relationships[table_name] = chunk.metadata[\"related_tables\"].split(\", \")\n",
    "    \n",
    "    return ddls, relationships\n",
    "\n",
    "# Create vector store with pre-filtered documents\n",
    "chunks, rel_graph = process_chunks(db)\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"cohere_schema\",\n",
    "    persist_directory=\"./chroma_cohere\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CohereRelationshipRetriever:\n",
    "    def __init__(self, vector_store, relationship_graph):\n",
    "        # Initialize with Chroma-compatible parameters\n",
    "        self.base_retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\"k\": 10}  # Adjust k as needed\n",
    "        )\n",
    "        self.relationship_graph = relationship_graph\n",
    "        \n",
    "    def find_related_chunks(self, table_name):\n",
    "        return [c for c in chunks if c.metadata[\"table_name\"] in self.relationship_graph.get(table_name, [])]\n",
    "    \n",
    "    def get_relevant_documents(self, query):\n",
    "        # Get base results with scores using similarity_search_with_score\n",
    "        docs_scores = self.base_retriever.vectorstore.similarity_search_with_score(query, k=15)\n",
    "        \n",
    "        # Filter by score manually\n",
    "        filtered_docs = [doc for doc, score in docs_scores if score < 0.28]\n",
    "        \n",
    "        # Expand relationships\n",
    "        expanded = []\n",
    "        seen = set()\n",
    "        \n",
    "        for doc in filtered_docs:\n",
    "            tbl = doc.metadata.get(\"table_name\")\n",
    "            if tbl and tbl not in seen:\n",
    "                expanded.append(doc)\n",
    "                seen.add(tbl)\n",
    "                # Add 1st-degree relationships\n",
    "                expanded += [d for d in self.find_related_chunks(tbl) \n",
    "                            if d.metadata[\"table_name\"] not in seen]\n",
    "                \n",
    "        return sorted(expanded, \n",
    "                    key=lambda x: -len(x.metadata[\"related_tables\"]))[:7]\n",
    "retriever = CohereRelationshipRetriever(vector_store, rel_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.get_relevant_documents(\n",
    "    \"Find customers who purchased tracks from more than 3 genres, \"\n",
    "    \"along with their total spending and favorite artist\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
